import streamlit as st
from datetime import datetime
import time
import polars as pl
from util import (
    get_db_engine,
    supabase_read_sql,
    supabase_execute_sql,
    fetch_user_roles,
    conn_str,
)

def main():

    st.set_page_config(
        page_title="æº¶å°„é›»æ¥µå‡ºè·çŠ¶æ³æ›´æ–°(é•·æ´¥å°‚ç”¨)",
        page_icon="ğŸšš",
        layout="wide",
        initial_sidebar_state="expanded",
    )
    st.title("æº¶å°„é›»æ¥µå‡ºè·çŠ¶æ³æ›´æ–°(é•·æ´¥å°‚ç”¨)")
    st.subheader("æº¶å°„é›»æ¥µã®å‡ºè·çŠ¶æ³ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§æ›´æ–°ã—ã¾ã™ã€‚")

    # èªè¨¼ã•ã‚Œã¦ã„ãªã„ã€ã¾ãŸã¯ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ãŒå­˜åœ¨ã—ãªã„å ´åˆ
    if "authenticated" not in st.session_state or not st.session_state.authenticated:
        st.warning("ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„ã€‚")
        time.sleep(2)
        st.switch_page("sign_in.py")
        return
    else:
        # èªè¨¼ã•ã‚Œã¦ã„ã‚‹å ´åˆ
        user_email = st.session_state.get("user_email", "ä¸æ˜ãªãƒ¦ãƒ¼ã‚¶ãƒ¼")
        user_roles_df = fetch_user_roles(email=user_email)
        user_name = user_roles_df["user_name"][0]
        last_sign_in = user_roles_df["last_sign_in_at"][0].strftime("%Y-%m-%d %H:%M:%S")
        created_at = user_roles_df["created_at"][0].strftime("%Y-%m-%d %H:%M:%S")
        role = user_roles_df["role"][0]
        can_read = user_roles_df["can_read"][0]
        can_write = user_roles_df["can_write"][0]
        email_confirmed_at = user_roles_df["email_confirmed_at"][0]
        if email_confirmed_at is None:
            st.warning(
                "ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãŒç¢ºèªã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç¢ºèªãƒ¡ãƒ¼ãƒ«ã‚’å†é€ä¿¡ã—ã¦ãã ã•ã„ã€‚"
            )
            time.sleep(2)
            st.switch_page("sign_in.py")
            return
        if role not in ["nagatsu", "admin"] or can_write == False:
            st.warning(
                "ã“ã®ãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“ã€‚  \n- ç®¡ç†è€…ã«æ¨©é™ä»˜ä¸ã‚’ç”³è«‹ã—ã¦ãã ã•ã„ã€‚\n- ã“ã®æ©Ÿèƒ½ã¯åŸºæœ¬çš„ã«é•·æ´¥ã‚°ãƒ«ãƒ¼ãƒ—å°‚ç”¨ã§ã™ã€‚"
            )
            return

        syukka_file = st.file_uploader(
            "å‡ºè·ã‚·ãƒªã‚¢ãƒ«ãƒ‡ãƒ¼ã‚¿(å°‚ç”¨ã®TSVãƒ•ã‚¡ã‚¤ãƒ«)ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ä¸‹ã•ã„",
            type="tsv",
            accept_multiple_files=False,
            width="stretch",
        )
        if syukka_file:
            try:
                with syukka_file as f:
                    update_df = pl.read_csv(f, separator="\t", has_header=True)
                    # ã‚®ã‚¬æ³¨ç•ª(giga_order_num)ã”ã¨ã®ã‚·ãƒªã‚¢ãƒ«(sirial_num)é †ã®é€£ç•ªã®åˆ—ã‚’ä½œæˆ
                    update_df = update_df.with_columns(
                        pl.col("sirial_num")
                        .rank(method="ordinal")
                        .over("giga_order_num")
                        .alias("edaban")
                        .cast(pl.Int32)
                    )
                    update_df = fetch_electrode_status_list(update_df)
                    updatable_df = update_df.filter(pl.col("exists") == True).drop("exists")
                    not_updatable_df = update_df.filter(pl.col("exists") == False).drop("exists")
                    
                    st.text("æ›´æ–°å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿")
                    st.dataframe(updatable_df, width="stretch")
                    if not_updatable_df.is_empty() == False:
                        st.warning(f"æ›´æ–°å‡ºæ¥ãªã„ãƒ‡ãƒ¼ã‚¿ãŒ{ not_updatable_df.shape(0) }ä»¶ã‚ã‚Šã¾ã™ã€‚")
                        st.dataframe(not_updatable_df, width="stretch")            
                    if updatable_df.is_empty() == False:
                        update_button = st.button("æ›´æ–°ã™ã‚‹", type="primary")
                        if update_button:
                            result = update_electrode_status_list(updatable_df)
                            if result:
                                st.success("æ›´æ–°ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
                            else:
                                st.error("æ›´æ–°ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")

       
            except Exception as e:
                st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                return

def fetch_electrode_status_list(update_df: pl.DataFrame) -> pl.DataFrame:
    """èª­ã¿è¾¼ã‚“ã å‡ºè·ã‚·ãƒªã‚¢ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å…ƒã«é›»æ¥µçŠ¶æ³è¡¨ã‚’æ›´æ–°å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    Args:
        update_df (pl.DataFrame): èª­ã¿è¾¼ã‚“ã å‡ºè·ã‚·ãƒªã‚¢ãƒ«ãƒ‡ãƒ¼ã‚¿
    Returns:
        pl.DataFrame: æ›´æ–°å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿
    """
    # schema_dict = {
    #     "giga_order_num": pl.String,
    #     "edaban": pl.Int32,
    #     "exists": pl.Boolean,
    # }
    exists_df = pl.DataFrame()
    for row in update_df.to_dicts():
        try:
            params = {
                "giga_order_num": row["giga_order_num"],
                "edaban": row["edaban"],
            }
        except Exception as e:
            st.error(f"æ›´æ–°å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return pl.DataFrame()

        query = """
SELECT
    es.id,
    es.item_code
FROM
    public.electrode_status es
WHERE
    es.giga_order_num = :giga_order_num
    AND es.edaban = :edaban
"""
        result_df = supabase_read_sql(query, parameters=params)
        if result_df.is_empty() == False:
            dict_exists={
                "giga_order_num": row["giga_order_num"],
                "edaban": row["edaban"],
                "exists": True,
            }
            exists_df = pl.concat([exists_df, pl.DataFrame([dict_exists])])
    try:
        updatable_df = update_df.join(exists_df, on=["giga_order_num", "edaban"], how="inner")
        return updatable_df
    except Exception as e:
        st.error(f"æ›´æ–°å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return pl.DataFrame()
    

                
            



def update_electrode_status_list(update_df: pl.DataFrame) -> bool:
    """èª­ã¿è¾¼ã‚“ã å‡ºè·ã‚·ãƒªã‚¢ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å…ƒã«é›»æ¥µçŠ¶æ³è¡¨ã‚’æ›´æ–°
    Args:
        update_df (pl.DataFrame): èª­ã¿è¾¼ã‚“ã å‡ºè·ã‚·ãƒªã‚¢ãƒ«ãƒ‡ãƒ¼ã‚¿
    Returns:
        bool: æ›´æ–°çµæœã®çœŸå½å€¤(True: æˆåŠŸ, False: å¤±æ•—)
    """
    queries = []
    for row in update_df.to_dicts():

        # å„ç¨®å±æ€§ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ ¼ç´
        params = {
            "giga_order_num": row["giga_order_num"],
            "shiped_date": row["shiped_date"],
            "sirial_num": row["sirial_num"],
            "edaban": row["edaban"],
        }

        # æ›´æ–°ç”¨ã‚¯ã‚¨ãƒª
        query = """
UPDATE public.electrode_status
SET shiped_date = :shiped_date,
    sirial_num = :sirial_num,
    status = 'OK',
    update_dt = now()
WHERE 
    public.electrode_status.giga_order_num = :giga_order_num
    AND public.electrode_status.edaban = :edaban
"""
        queries.append({"sql": query, "params": params})
    result = supabase_execute_sql(queries)
    return result


if __name__ == "__main__":
    main()
